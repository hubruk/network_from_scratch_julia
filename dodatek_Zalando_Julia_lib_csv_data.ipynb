{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network structure rework: split into 3 different structures: network, batch_trainer and batch_tester for preallocation\n",
    "# the whole run time is faster due to preallocation for evaluation batch (batch_tester)\n",
    "using LinearAlgebra\n",
    "using MLDatasets\n",
    "using Random\n",
    "using Plots\n",
    "using Debugger\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "@inline σ(z) = 1/(1+exp(-z))        #sigmoid function\n",
    "@inline σ_grad(z) = σ(z)*(1-σ(z))   #grad of sigmoid function\n",
    "\n",
    "struct network\n",
    "    num_layers::Int64\n",
    "    sizearr::Array{Int64,1}\n",
    "    biases::Array{Array{Float64,1},1}\n",
    "    weights::Array{Array{Float64,2},1}\n",
    "end\n",
    "function network(sizes)\n",
    "    num_layers = length(sizes)\n",
    "    sizearr = sizes\n",
    "    biases = [randn(y) for y in sizes[2:end]]\n",
    "    weights = [randn(y, x) for (x, y) in zip(sizes[1:end-1], sizes[2:end])]\n",
    "    network(num_layers, sizearr, biases, weights)\n",
    "end\n",
    "function (net::network)(a)\n",
    "    for (w, b) in zip(net.weights, net.biases)\n",
    "        a = σ.(w*a .+ b)\n",
    "    end\n",
    "    return a\n",
    "end\n",
    "\n",
    "struct batch_trainer\n",
    "    η::Float64\n",
    "    batch_size::Int64\n",
    "    ∇_b::Array{Array{Float64,1},1}\n",
    "    ∇_w::Array{Array{Float64,2},1}\n",
    "    zs::Array{Array{Float64,2},1}\n",
    "    activations::Array{Array{Float64,2},1}\n",
    "    δs::Array{Array{Float64,2},1}\n",
    "end\n",
    "function batch_trainer(net::network, batch_size, η)\n",
    "    sizes = net.sizearr\n",
    "    ∇_b = [zeros(y) for y in sizes[2:end]]\n",
    "    ∇_w = [zeros(y, x) for (x, y) in zip(sizes[1:end-1], sizes[2:end])]\n",
    "    zs = [zeros(y, batch_size) for y in sizes[2:end]]\n",
    "    activations = [zeros(y, batch_size) for y in sizes[2:end]]\n",
    "    δs = [zeros(y, batch_size) for y in sizes[2:end]]\n",
    "    batch_trainer(η, batch_size, ∇_b, ∇_w, zs, activations, δs)\n",
    "end\n",
    "\n",
    "struct batch_tester\n",
    "    batch_size::Int64\n",
    "    zs::Array{Array{Float64,2},1}\n",
    "    activations::Array{Array{Float64,2},1}\n",
    "    δs::Array{Array{Float64,2},1}\n",
    "end\n",
    "function batch_tester(net::network, batch_size)\n",
    "    sizes = net.sizearr\n",
    "    zs = [zeros(y, batch_size) for y in sizes[2:end]]\n",
    "    activations = [zeros(y, batch_size) for y in sizes[2:end]]\n",
    "    δs = [zeros(y, batch_size) for y in sizes[2:end]]\n",
    "    batch_tester(batch_size, zs, activations, δs)\n",
    "end\n",
    "\n",
    "# forward pass for testing\n",
    "function (tester::batch_tester)(net::network, x)\n",
    "    activations = tester.activations\n",
    "    zs = tester.zs\n",
    "    len = length(activations)\n",
    "\n",
    "\tinput = x\n",
    "    for i in 1:len\n",
    "        b, w, z = net.biases[i], net.weights[i], zs[i]\n",
    "        mul!(z, w, input) # z = w * input\n",
    "        z .+= b\n",
    "        activations[i] .= σ.(z)\n",
    "        input = activations[i]\n",
    "    end\n",
    "    return activations[end]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# forward and backprop for training\n",
    "function (trainer::batch_trainer)(net::network, x, y)\n",
    "    ∇_b = trainer.∇_b\n",
    "    ∇_w = trainer.∇_w\n",
    "    #println(∇_w)\n",
    "\tlen = net.num_layers - 1\n",
    "    activations = trainer.activations\n",
    "    zs = trainer.zs\n",
    "    δs = trainer.δs\n",
    "\n",
    "    input = x\n",
    "\n",
    "    for i in 1:len\n",
    "        b, w, z = net.biases[i], net.weights[i], zs[i]\n",
    "        mul!(z, w, input) # z = w * input\n",
    "        z .+= b\n",
    "        activations[i] .= σ.(z)\n",
    "        input = activations[i]\n",
    "    end\n",
    "\n",
    "\n",
    "    δ = δs[end]\n",
    "    δ .= (activations[end] .- y) .* σ_grad.(zs[end])\n",
    "\n",
    "    # println(\"input1 \", length(input), \"przykład \", sum(input))\n",
    "    # println(\"δ1 \", length(δ), \"przykład \", δ[1], \"\\n\")\n",
    "\n",
    "    sum!(∇_b[end], δ)\n",
    "\n",
    "\n",
    "    #backprop, 3 layers = 1 loop (because u only need middle layer to update)\n",
    "    for l in 1:len-1\n",
    "        #print(len-1, \"\\n\")\n",
    "        mul!(∇_w[end-l+1], δ, activations[end-l]') # ∇_w[end-l+1] = δ * activations[end-l]'\n",
    "        z = zs[end-l]\n",
    "        mul!(δs[end-l], net.weights[end-l+1]', δ) # δs[end-l] = net.weights[end-l+1]' * δ\n",
    "        δ = δs[end-l]\n",
    "        δ .*= σ_grad.(z)\n",
    "        sum!(∇_b[end-l], δ)\n",
    "    end\n",
    "\n",
    "\n",
    "    #println(\"δ2 \", length(δ), \"przykład \", δ[1], \"\\n\")\n",
    "\n",
    "    #print(size(∇_w), \"   /   \", size(∇_w[1]))\n",
    "    mul!(∇_w[1], δ, x') # ∇_w[1] = δ * x'\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function update_batch(net::network, trainer::batch_trainer, x, y)\n",
    "\n",
    "    trainer(net, x, y)\n",
    "\n",
    "    global coef = trainer.η/size(x,2) \n",
    "\n",
    "    for i in 1:length(trainer.∇_b)\n",
    "        net.biases[i] .-= coef .* trainer.∇_b[i]\n",
    "    end\n",
    "    for i in 1:length(trainer.∇_w)\n",
    "        net.weights[i] .-= coef .* trainer.∇_w[i]\n",
    "    end\n",
    "    return x, y\n",
    "end\n",
    "\n",
    "function SGDtrain(net::network, trainer::batch_trainer, traindata, epochs, tester, testdata=nothing)\n",
    "\n",
    "    #println(\"len?\", length(traindata[2]), \"     \")\n",
    "\n",
    "    n_test = testdata != nothing ? size(testdata[1], 2) : nothing\n",
    "    n = size(traindata[1], 2)\n",
    "\n",
    "    idx = randperm(n) # one time shuffle for performance, then only take random batch index\n",
    "    # idx = 1:n\n",
    "    train_x = traindata[1][:,idx]\n",
    "    train_y = traindata[2][:,idx]\n",
    "    test_x, test_y = testdata\n",
    "\t\n",
    "\tbatch_size = trainer.batch_size\n",
    "    # reorganize data in batches\n",
    "    batch = [(train_x[:, k-batch_size+1 : k], train_y[:, k-batch_size+1 : k]) for k in batch_size:batch_size:n]\n",
    "    #println(length(batch))\n",
    "\n",
    "        #println(\"START\")\n",
    "    get_precision = []\n",
    "    for j in 1:epochs\n",
    "        idx = randperm(length(batch))\n",
    "        #println(length(idx))\n",
    "        for k in idx\n",
    "            update_batch(net, trainer, batch[k]...)\n",
    "        end\n",
    "\n",
    "        if testdata != nothing\n",
    "            true_positive = evaluate(tester(net, test_x), test_y) \n",
    "            #println(true_positive)\n",
    "            #println(length(test_y))\n",
    "            false_positive = true_positive - tester.batch_size\n",
    "            #println(\"\\n\", true_positive, \"    \", tester.batch_size,\"\\n\")\n",
    "            precision = true_positive/ length(test_y)\n",
    "            push!(get_precision, precision)\n",
    "            #println(\"Epoch \", j,\" with \", \"precision: \",precision)\n",
    "            #println(length(evaluate(tester(net, test_x))), \":::::\", length(test_y))\n",
    "            #println(tester(net, test_x), test_y[1:10])\n",
    "        else\n",
    "            #println(\"Epoch \", j,\" complete.\")\n",
    "        end\n",
    "    end\n",
    "    return get_precision\n",
    "end\n",
    "\n",
    "function evaluate(out, y)\n",
    "    hits = 0\n",
    "    for i = 1:size(out, 2)\n",
    "        if (findmax(out[:,i])[2] - 1) == y[i]\n",
    "            #println(findmax(out[:,i])[2] - 1, \"lllllll\", y[i])\n",
    "            hits += 1\n",
    "        end\n",
    "    end\n",
    "    hits\n",
    "end\n",
    "\n",
    "function loaddata_lib(rng = 1:60000)\n",
    "\n",
    "    #print(\"czas ładowania samych danych bez przekształceń:\")\n",
    "    train_x, train_y = FashionMNIST.traindata(Float64, Vector(rng))\n",
    "    train_x = reshape(train_x, size(train_x,1)*size(train_x,2), :) # 28 x 28 x N -> 28*28 x N\n",
    "    train_y = vectorize(train_y)\n",
    "    test_x, test_y = FashionMNIST.testdata(Float64)\n",
    "    test_x = reshape(test_x, size(test_x,1)*size(test_x,2), :) # 28 x 28 x N -> 28*28 x N\n",
    "    #println(size(train_x), size(train_y), size(test_x), size(test_y))\n",
    "    #println(typeof(train_x), typeof(train_y), typeof(test_x), typeof(test_y))\n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "end\n",
    "\n",
    "function loaddata_csv(rng = 1:60000)\n",
    "    \n",
    "    \n",
    "    #train_x, train_y = FashionMNIST.traindata(Float64, Vector(rng))\n",
    "\n",
    "\n",
    "    #print(\"czas ładowania samych danych bez przekształceń:\")\n",
    "    data_test = CSV.read(\"C:/Users/krukd/project_julia_net_scrath/fashion_mnist_test.csv\", DataFrame)\n",
    "    data_train = CSV.read(\"C:/Users/krukd/project_julia_net_scrath/fashion_mnist_train.csv\", DataFrame)\n",
    "    #println(\"/n\")\n",
    "    #print(typeof(data_test))\n",
    "    #print(typeof(data_train))\n",
    "    data_test = Matrix{Float64}(data_test)\n",
    "    data_train = Matrix{Float64}(data_train)\n",
    "    tr_m, tr_n = size(data_train)\n",
    "    #print(tr_m, \"  train  \",tr_n, \"\\n\")\n",
    "    ts_m, ts_n = size(data_test)\n",
    "    #print(ts_m, \"  tesst  \",ts_n, \"\\n\")\n",
    "\n",
    "    data_test = data_test[1:ts_m,:]' #transponowanie po to, aby każda kolumna to był przykład\n",
    "    test_y = data_test[1,:]\n",
    "    test_x = data_test[2:ts_n,:]\n",
    "    #print(size(data_test), '\\n', size(Y_test), '\\n', size(X_test))\n",
    "    test_x = test_x / 255.\n",
    "\n",
    "    data_train = data_train[1:tr_m, :]'\n",
    "    train_y = data_train[1, :]\n",
    "    train_x = data_train[2:tr_n, :]\n",
    "    train_x = train_x / 255.\n",
    "    _,m_train = size(train_x)\n",
    "\n",
    "    #train_x = reshape(train_x, size(train_x,1)*size(train_x,2), :) # 28 x 28 x N -> 28*28 x N\n",
    "    train_y = vectorize(train_y)\n",
    "    #test_x, test_y = FashionMNIST.testdata(Float64)\n",
    "    #test_x = reshape(test_x, size(test_x,1)*size(test_x,2), :) # 28 x 28 x N -> 28*28 x N\n",
    "    \n",
    "    #println(size(train_x), size(train_y), size(test_x), size(test_y))\n",
    "    #println(typeof(train_x), typeof(train_y), typeof(test_x), typeof(test_y))\n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "end\n",
    "\n",
    "function vectorize(vec)\n",
    "    N = 10\n",
    "    len = length(vec)\n",
    "    mtx = zeros(N, len)\n",
    "    for i = 1:len\n",
    "        mtx[Int64(vec[i])+1, i] = 1\n",
    "    end\n",
    "    return mtx\n",
    "end\n",
    "\n",
    "function main(epochs, batch_size, coefi)\n",
    "    get_accuracy = []\n",
    "    epochs = epochs\n",
    "    batch_size = batch_size\n",
    "    η = coefi\n",
    "    net = network([784, 10, 10])\n",
    "    #println(\"czas twania loaddata z biblio:\")\n",
    "    #println(epochs, \" \", batch_size)\n",
    "\ttrainer = batch_trainer(net, batch_size, η)\n",
    "\ttester = batch_tester(net, size(testdata[1],2))\n",
    "    global prec = SGDtrain(net, trainer, traindata, epochs, tester, testdata)\n",
    "    # @profiler SGDtrain(net, trainer, traindata, 1, tester, testdata)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 1.0 0.0; 0.0 1.0 … 0.0 0.0]), ([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.00392156862745098 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 8.0, 6.0, 5.0, 0.0  …  7.0, 9.0, 4.0, 8.0, 0.0, 0.0, 6.0, 8.0, 8.0, 1.0]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata, testdata = loaddata_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata, testdata = loaddata_lib();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using UUIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tester (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tester(epochs, batch_size, coefi, coef_step, tests)\n",
    "    plot(titlefontsize = 12)\n",
    "    for i=1:tests\n",
    "        if i == 1\n",
    "            coefi = coefi\n",
    "        else \n",
    "            coefi = coefi + (coef_step * i)\n",
    "        end\n",
    "        a = @timed main(epochs, batch_size, coefi);\n",
    "        plot!(1:epochs, prec, label = string(trunc(Int, round(a.time)), \"sec epochs:\", epochs, \" batch_size:\", batch_size, \" alpha:\", round(coef, digits = 6)), lw = 4)\n",
    "        println(\"max prec in last 10 tests was: \", findmax(prec[end-20:end]), \" alpha:\", coef)\n",
    "    end\n",
    "\n",
    "    plot!(size=(1200,600))\n",
    "    plot!(dpi=120)\n",
    "    plot!(grid = true)\n",
    "\n",
    "    png(string(\"C:/Users/krukd/project_julia_net_scrath/plots_bez_auto/\", \"tester_\", uuid4()))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs, batch_size, coef, coef_step, tests\n",
    "tester(100, 1, 1.25, 0.05, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prec in last 10 tests was: (0.8424, 11) alpha:0.25\n",
      "max prec in last 10 tests was: (0.8436, 8) alpha:0.41\n",
      "max prec in last 10 tests was: (0.8315, 5) alpha:0.65\n",
      "max prec in last 10 tests was: (0.8269, 10) alpha:0.97\n",
      "max prec in last 10 tests was: (0.8289, 11) alpha:1.3699999999999999\n"
     ]
    }
   ],
   "source": [
    "#epochs, batch_size, coef, coef_step, tests\n",
    "tester(100, 5, 1.25, 0.4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prec in last 10 tests was: (0.8398, 9) alpha:0.08333333333333333\n",
      "max prec in last 10 tests was: (0.84, 1) alpha:0.13666666666666666\n",
      "max prec in last 10 tests was: (0.8448, 4) alpha:0.21666666666666667\n",
      "max prec in last 10 tests was: (0.8443, 5) alpha:0.3233333333333333\n",
      "max prec in last 10 tests was: (0.8399, 9) alpha:0.45666666666666667\n"
     ]
    }
   ],
   "source": [
    "#epochs, batch_size, coef, coef_step, tests\n",
    "tester(100, 15, 1.25, 0.4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prec in last 10 tests was: (0.8446, 2) alpha:0.025\n",
      "max prec in last 10 tests was: (0.8454, 7) alpha:0.040999999999999995\n",
      "max prec in last 10 tests was: (0.8432, 5) alpha:0.065\n",
      "max prec in last 10 tests was: (0.8464, 10) alpha:0.09699999999999999\n",
      "max prec in last 10 tests was: (0.8402, 3) alpha:0.13699999999999998\n"
     ]
    }
   ],
   "source": [
    "#epochs, batch_size, coef, coef_step, tests\n",
    "tester(100, 50, 1.25, 0.4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prec in last 10 tests was: (0.815, 9) alpha:0.0025\n",
      "max prec in last 10 tests was: (0.7965, 10) alpha:0.0040999999999999995\n",
      "max prec in last 10 tests was: (0.829, 10) alpha:0.0065\n",
      "max prec in last 10 tests was: (0.8328, 9) alpha:0.009699999999999999\n",
      "max prec in last 10 tests was: (0.8456, 7) alpha:0.013699999999999999\n"
     ]
    }
   ],
   "source": [
    "#epochs, batch_size, coef, coef_step, tests\n",
    "tester(100, 500, 1.25, 0.4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max prec in last 10 tests was: (0.6655, 11) alpha:0.000125\n",
      "max prec in last 10 tests was: (0.7678, 7) alpha:0.000325\n",
      "max prec in last 10 tests was: (0.794, 10) alpha:0.000625\n",
      "max prec in last 10 tests was: (0.7743, 9) alpha:0.001025\n",
      "max prec in last 10 tests was: (0.813, 5) alpha:0.001525\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#epochs, batch_size, coef, coef_step, tests\n",
    "tester(300, 10000, 1.25, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[7742, 8162, 8237, 8052, 8336, 8342, 8309, 8293, 8396, 8188, 8241]\n"
     ]
    }
   ],
   "source": [
    "# epochs = 11\n",
    "# batch_size = 5\n",
    "# coef = 1.25\n",
    "# a = @timed main(epochs, batch_size, coef);\n",
    "# plot(1:epochs, prec, title = string(a.time, \"sec epochs:\", epochs, \" batch_size:\", batch_size, \" alpha:\", coef), label = \"\")\n",
    "# plot!(titlefontsize = 12)\n",
    "# println(prec[end-10:end])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86a3b408b4271ef552defcd529bf66fef01029da2a6c1ae2298bb37f1f91afe2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
